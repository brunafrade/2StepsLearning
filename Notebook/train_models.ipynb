{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_models.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPI2Y1SaffmMqGgYAcgrtKJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brunafrade/2StepsLearning/blob/main/Notebook/train_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpBt2WK8_fR-",
        "outputId": "84ea71cf-eb70-403e-8fe7-9bdde637c30f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#!pip install keras==2.0\n",
        "#!pip install tensorflow==1.15.0\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "from tensorflow import keras\n",
        "from keras import backend as k\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten,GlobalAveragePooling2D\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.core import Activation, Dropout, Dense, Reshape\n",
        "\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "# from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.optimizers import gradient_descent_v2,adam_v2,rmsprop_v2\n",
        "# from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.constraints import maxnorm\n",
        "from keras import optimizers\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "import os\n",
        "from pandas.io.parsers import read_csv\n",
        "import os\n",
        "import gzip\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "import numpy as np\n",
        "import gzip\n",
        "from keras.utils import np_utils\n",
        "import socket\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def get_session(gpu_fraction=0.2):\n",
        "    '''Assume that you have 6GB of GPU memory and want to allocate ~2GB'''\n",
        "\n",
        "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
        "    gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
        "\n",
        "    if num_threads:\n",
        "        return tf.Session(config=tf.ConfigProto(\n",
        "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
        "    else:\n",
        "        return tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))"
      ],
      "metadata": {
        "id": "W47CLFwfEwrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_folder(directory):\n",
        "\tif not os.path.exists(directory):\n",
        "\t\tos.makedirs(directory)\n",
        "def cross_validation(X_train,Y_train,train_index,test_index):\n",
        "    # kf = KFold(n_splits=5)\n",
        "    # fold=0\n",
        "    # for (train_index, test_index) in kf.split(X_train):\n",
        "    X_src_tr= np.zeros([train_index.shape[0],32,32,1])\n",
        "    X_src_tes= np.zeros([test_index.shape[0],32,32,1])\n",
        "    y_src_tr= np.zeros([train_index.shape[0],6])\n",
        "    y_src_tes= np.zeros([test_index.shape[0],6])\n",
        "\n",
        "\n",
        "    j=0\n",
        "    for index_train in train_index:\n",
        "\n",
        "        X_src_tr[j] = X_train[index_train]\n",
        "        y_src_tr[j] = Y_train[index_train]\n",
        "        \n",
        "        j+=1\n",
        "\n",
        "    j=0\n",
        "    for index_test in  test_index:\n",
        "\n",
        "        X_src_tes[j] = X_train[index_test]\n",
        "        y_src_tes[j] = Y_train[index_test]\n",
        "        \n",
        "        j+=1\n",
        "\n",
        "    return X_src_tr,y_src_tr,X_src_tes,y_src_tes\n",
        "\n",
        "def preprocess_images(X, tmin=-1, tmax=1):\n",
        "\tV = X * (tmax - tmin) / 255.\n",
        "\tV += tmin\n",
        "\treturn V\n",
        "\n",
        "def postprocess_images(V, omin=-1, omax=1):\n",
        "\tX = V - omin\n",
        "\tX = X * 255. / (omax - omin)\n",
        "\treturn X\n",
        "\n",
        "def show_images(Xo, padsize=1, padval=0, filename=None, title=None):\n",
        "\t# data format : channel_first\n",
        "\tX = np.copy(Xo)\n",
        "\t[n, d1, d2, c] = X.shape\n",
        "\tif c== 1:\n",
        "\t\tX = np.reshape(X, (n, d1, d2))\n",
        "\n",
        "\tn = int(np.ceil(np.sqrt(X.shape[0])))\n",
        "\t\n",
        "\tpadding = ((0, n ** 2 - X.shape[0]), (0, padsize), (0, padsize)) + ((0, 0), ) * (X.ndim - 3)\n",
        "\tcanvas = np.pad(X, padding, mode='constant', constant_values=(padval, padval))\n",
        "\n",
        "\tcanvas = canvas.reshape((n, n) + canvas.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, canvas.ndim + 1)))\n",
        "\tcanvas = canvas.reshape((n * canvas.shape[1], n * canvas.shape[3]) + canvas.shape[4:])\n",
        "\n",
        "\tif title is not None:\n",
        "\t\ttitle_canv = np.zeros((50, canvas.shape[1]))\n",
        "\t\ttitle_canv = title_canv.astype('uint8')\n",
        "\t\tcanvas = np.vstack((title_canv, canvas)).astype('uint8')\n",
        "\t\t\n",
        "\t\tI = Image.fromarray(canvas)\n",
        "\t\td = ImageDraw.Draw(I)\n",
        "\t\tfill = 255\n",
        "\t\td.text((10, 10), title, fill=fill, font=fnt)\n",
        "\telse:\n",
        "\t\tcanvas = canvas.astype('uint8')\n",
        "\t\tI = Image.fromarray(canvas)\n",
        "\n",
        "\tif filename is None:\n",
        "\t\tI.show()\n",
        "\telse:\n",
        "\t\tI.save(filename)\n",
        "\n",
        "\treturn I\n",
        "def read_dhiego_dataset(FTRAIN_source):\n",
        "\n",
        "\n",
        "\t\tdf_train_src = read_csv(os.path.expanduser(FTRAIN_source))  # load pandas dataframe\n",
        "\t \t\n",
        "\t\tdf_train_src['image'] = df_train_src['image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
        "\t\t\n",
        "\t\tdf_train_src = df_train_src.dropna()  # drop all rows that have missing values in them\n",
        "\t\t\n",
        "\t\t\n",
        "\t\tX_train_src = np.vstack(df_train_src['image'].values)   # scale pixel values to [0, 1]\n",
        "\t\tX_train_src = X_train_src.astype(np.uint8)\n",
        "\n",
        "\t\t\n",
        "\t\ty_train_src = df_train_src[df_train_src.columns[:-1]].values\n",
        "\t\ty_train_src = y_train_src.astype(np.uint8)\n",
        "\n",
        "\t\ty_train_src=y_train_src/32.\n",
        "\n",
        "\t\tX_train_src = X_train_src.reshape(X_train_src.shape[0], 32, 32, 1)\n",
        "\n",
        "\t\t\n",
        "\n",
        "\t\treturn X_train_src,y_train_src\n",
        "def load(FTRAIN_source):\n",
        "    df_train_src = read_csv(os.path.expanduser(FTRAIN_source))  # load pandas dataframe\n",
        "\n",
        "    # The Image column has pixel values separated by space; convert\n",
        "    # the values to numpy arrays:\n",
        "    df_train_src['image'] = df_train_src['image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
        "    \n",
        "    print('source ',df_train_src.count())  # prints the number of values for each column\n",
        "\n",
        "    df_train_src = df_train_src.dropna()  # drop all rows that have missing values in them\n",
        "\n",
        "    X_train_src = np.vstack(df_train_src['image'].values)/255.   # scale pixel values to [0, 1]\n",
        "\n",
        "    X_train_src = X_train_src.astype('float32')\n",
        "\n",
        "\n",
        "    df_train_src['image_gt'] = df_train_src['image_gt'].apply(lambda im: np.fromstring(im, sep=' '))\n",
        "    \n",
        "    print('source ',df_train_src.count())  # prints the number of values for each column\n",
        "\n",
        "    df_train_src = df_train_src.dropna()  # drop all rows that have missing values in them\n",
        "\n",
        "    gt_train_src = np.vstack(df_train_src['image_gt'].values)/255   # scale pixel values to [0, 1]\n",
        "    # gt_train_src = gt_train_src.astype('float32')\n",
        "\n",
        "    y_train_src = (df_train_src[df_train_src.columns[:-2]].values )\n",
        "\n",
        "   \n",
        "    \n",
        "   \n",
        "    # y_train_src = y_train_src.astype('uint8')\n",
        "    # idx10 = np.where(y_train_src > 32)\n",
        "    # y_train_src[idx10] = 1\n",
        "    # print y_train_src\n",
        "    #y_train_src=y_train_src/32.\n",
        "    y_train_src=(y_train_src-16)/16.\n",
        "\n",
        "    X_train_src = X_train_src.reshape(X_train_src.shape[0], 32, 32, 1)\n",
        "    gt_train_src = gt_train_src.reshape(gt_train_src.shape[0], 32, 32, 3)\n",
        "    # y_train_src = y_train_src.reshape(y_train_src.shape[0],1,1,6)\n",
        "    y_train_src = y_train_src.reshape(y_train_src.shape[0],6)\n",
        "    return X_train_src,gt_train_src,y_train_src\n",
        "\n",
        "def get_impulse_noise(X, level):\n",
        "\tp = 1. - level\n",
        "\tY = X * np.random.binomial(1, p, size=X.shape)\n",
        "\treturn Y\n",
        "\n",
        "def get_gaussian_noise(X, std):\n",
        "\t# X: [n, c, d1, d2] images in [0, 1]\n",
        "\tY = np.random.normal(X, scale=std)\n",
        "\tY = np.clip(Y, 0., 1.)\n",
        "\treturn Y\t\n",
        "\n",
        "def get_flipped_pixels(X):\n",
        "\t# X: [n, c, d1, d2] images in [0, 1]\n",
        "\tY = 1. - X\n",
        "\tY = np.clip(Y, 0., 1.)\n",
        "\treturn Y\n",
        "\n",
        "\n",
        "def iterate_minibatches(inputs, targets, batchsize=128, shuffle=True):\n",
        "\n",
        "\tassert len(inputs) == len(targets)\n",
        "\n",
        "\tif shuffle:\n",
        "\t\tindices = np.arange(len(inputs))\n",
        "\t\tnp.random.shuffle(indices)\n",
        "\n",
        "\tfor start_idx in range(0, len(inputs), batchsize):\n",
        "\t\tend_idx = start_idx + batchsize\n",
        "\t\tif end_idx > len(inputs):\n",
        "\t\t\tend_idx = start_idx + (len(inputs) % batchsize)\n",
        "\n",
        "\t\tif shuffle:\n",
        "\t\t\texcerpt = indices[start_idx:end_idx]\n",
        "\t\n",
        "\t\telse:\n",
        "\t\t\texcerpt = slice(start_idx, end_idx)\n",
        "\n",
        "\t\tyield (inputs[excerpt], targets[excerpt])\n",
        "\n",
        "\n",
        "\n",
        "def save_weights(model, PARAMDIR, CONF):\n",
        "\t# model: keras model\n",
        "\tprint(' == save weights == ')\n",
        "\tprint (PARAMDIR)\n",
        "\n",
        "\t# save weights\n",
        "\tPARAMPATH = os.path.join(PARAMDIR, '%s_weights.h5') % CONF\n",
        "\tmodel.save(PARAMPATH)\n",
        "\t\n",
        "\t# save architecture\n",
        "\tCONFPATH = os.path.join(PARAMDIR, '%s_conf.json') % CONF\n",
        "\tarchjson = bytes(model.to_json(), 'utf-8')\n",
        "\n",
        "\topen(CONFPATH, 'wb').write(archjson)\n",
        "\n",
        "\n",
        "def clip_relu(x):\n",
        "\ty = K.maximum(x, 0)\n",
        "\treturn K.minimum(y, 1)\n",
        "\n",
        "\n",
        "\n",
        "# def plot_sample(x, y,axis):\n",
        "# \t# y=y.reshape(6)\n",
        "# \timg = x.reshape(32, 32)\n",
        "# \taxis.imshow(img,cmap='gray')\n",
        "# \taxis.scatter(y[0]*32 , y[1]*32 , marker='<', s=5)\n",
        "# \taxis.scatter(y[2]*32 , y[3]*32 , marker='>', s=5)\n",
        "# \taxis.scatter(y[4]*32 , y[5]*32 , marker='o', s=5)\n",
        "\n",
        "\t#axis.scatter(y[6]*32 , y[7]*32 , marker='o', s=5)\n",
        "\t#axis.scatter(y[8]*32 , y[9]*32 , marker='o', s=5)\n",
        "\t#axis.scatter(y[10]*32 , y[11]*32 , marker='o', s=5)\n",
        "\t#axis.scatter(y[12]*32 , y[13]*32 , marker='o', s=5)\n",
        "\t#axis.scatter(y[14]*32 , y[15]*32 , marker='o', s=5)\n",
        "\t#axis.scatter(y[16]*32 , y[17]*32 , marker='o', s=5)\n",
        "\t#axis.scatter(y[18]*32 , y[19]*32 , marker='o', s=5)\n",
        "def plot_sample(x, y,axis):\n",
        "\t#y=y.reshape(6)\n",
        "\timg = x.reshape(32, 32)\n",
        "\taxis.imshow(img,cmap='gray')\n",
        "\t#axis.scatter(y[0]*16.+16 , y[1]*16.+16 , marker='<', s=15)\n",
        "\t#axis.scatter(y[2]*16.+16 , y[3]*16.+16 , marker='>', s=15)\n",
        "\t#axis.scatter(y[4]*16.+16 , y[5]*16.+16 , marker='o', s=15)\n",
        "def visualization (model, x_heat,x,PARAMDIR,image_name):\n",
        "# visualization \n",
        "\t\t\n",
        "\tXs = x_heat[:36]\n",
        "\t# Xs = x\n",
        "\t# print Xs\n",
        "\t# Xs = postprocess_images(Xs, omin=0, omax=1)\n",
        "\t# Xs = np.reshape(Xs, (len(Xs), Xs.shape[3], Xs.shape[1], Xs.shape[2]))\n",
        "\t# #show_images(Xs, filename=image_name)\t\t\t\t\n",
        "\t# Xs_pred = drcn.convae_model.predict(Xs)\n",
        "\t# Xs_pred = postprocess_images(Xs_pred, omin=0, omax=1)\n",
        "\t# Xs_pred = np.reshape(Xs_pred, (len(Xs_pred), Xs_pred.shape[3], Xs_pred.shape[1], Xs_pred.shape[2]))\n",
        "\t# imgfile = PARAMDIR+'saida_autoencoder/o_'+image_name\n",
        "\t# show_images(Xs, filename=imgfile)\n",
        "\timgfile = PARAMDIR+'/saida_autoencoder/'+image_name\n",
        "\n",
        "\t# show_images(Xs_pred, filename=imgfile)\n",
        "\n",
        "\tXz = model.predict(x_heat[:36])\n",
        "\tXz = postprocess_images(Xz, omin=0, omax=1)\n",
        "\tXz = np.reshape(Xz, (len(Xz), Xz.shape[3], Xz.shape[1], Xz.shape[2]))\n",
        "\tfig = plt.figure(figsize=(1, 1))\n",
        "\tfig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "\tfor i in range(Xs.shape[0]):\n",
        "\t\tax = fig.add_subplot(np.sqrt(Xs.shape[0]), np.sqrt(Xs.shape[0]), i + 1, xticks=[], yticks=[])\n",
        "\t\tplot_sample(Xz[i],[0], ax)\n",
        "\t\n",
        "\tfig.savefig(imgfile)\n",
        "\n",
        "\tplt.close()\n",
        "\n",
        "def new_accuracy(keypoint_pred, keypoint_gt):\n",
        "    keypoint_pred=keypoint_pred.reshape(keypoint_pred.shape[0],6)\n",
        "    keypoint_gt=keypoint_gt.reshape(keypoint_gt.shape[0],6)\n",
        "    # Tamanhos incompativeis\n",
        "    if keypoint_pred.shape != keypoint_gt.shape:\n",
        "        return\n",
        "\n",
        "    # Coordenadas faltando\n",
        "    if (keypoint_pred.shape[1] % 2 != 0) | (keypoint_gt.shape[1] % 2 != 0):\n",
        "        return\n",
        "    # print keypoint_pred\n",
        "    THRESHOLD = 0.1\n",
        "    FACE_SIZE = 2\n",
        "    FAILURE_COUNT = 0\n",
        "    euc_dist = np.zeros((keypoint_gt.shape[0], int(keypoint_gt.shape[1]/2)))\n",
        "\n",
        "    # Supondo que os pontos estao ordenados em X, Y, X, Y, X, Y...\n",
        "    for i in range(int(keypoint_gt.shape[1]/2)):\n",
        "        euc_dist[:, i] = np.sqrt((keypoint_pred[:, 2*i] - keypoint_gt[:, 2*i])**2 + (keypoint_pred[:, 2*i + 1] - keypoint_gt[:, 2*i + 1])**2)\n",
        "        \n",
        "        for j in range(keypoint_gt.shape[0]):\n",
        "            if euc_dist[j, i] > (THRESHOLD * FACE_SIZE):\n",
        "                FAILURE_COUNT += 1\n",
        "\n",
        "    AVG_FAILURE_RATE = float(FAILURE_COUNT) / (keypoint_gt.shape[0] * keypoint_gt.shape[1]/2)\n",
        "\n",
        "    return 1 -AVG_FAILURE_RATE  \n"
      ],
      "metadata": {
        "id": "8ENfgJ5zSYEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_grafic(gen_loss,losses,val_losses,test_losses,epoca, dire):\n",
        "\t\n",
        "\n",
        "\t\n",
        "\tplt.plot( epoca, gen_loss, 'k:',label='rec_cat', color='orange') # linha pontilha orange\n",
        "\n",
        "\tplt.plot( epoca, losses, 'k:',label='trei_detec_hum', color='blue')  # linha tracejada azul\n",
        "\t\n",
        "\tplt.plot( epoca, val_losses, 'k--',label='detec_hum', color='black')  # linha tracejada azul\n",
        "\t\n",
        "\tplt.plot( epoca, test_losses, 'k--',label='detec_cat', color='green')  # linha tracejada azul\n",
        "\n",
        "\tplt.axis([0, 500, 0, 0.2])\n",
        "\tplt.title(\"Autoencoder:treino\")\n",
        "\tplt.legend()\n",
        "\tplt.grid(True)\n",
        "\tplt.xlabel(\"Epoca\")\n",
        "\tplt.ylabel(\"Erro\")\n",
        "\tplt.savefig(dire+\"/grafic_{}.png\".format(len(epoca)))\n",
        "\tplt.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MODEL(object):\n",
        "\tdef __init__(self, name='svhn-mnist'):\n",
        "\t\t\"\"\"\n",
        "\t\tClass constructor\n",
        "\t\t\"\"\"\n",
        "\t\tself.name = name\n",
        "\n",
        "\tdef extract_feat(self, _input, dense_dim=1000, dy=10, nb_filters=[64, 128], kernel_size=(3, 3), pool_size=(2, 2), \n",
        "\t\t\tdropout=0.5, bn=True, output_activation='softmax', opt='adam',trainable=True):\n",
        "\n",
        "\t\t\t_h = _input\n",
        "\n",
        "\t\t\t\n",
        "\t\t\t# _h = Conv2D(24, (5, 5), border_mode='same', init='he_normal',activation='relu')(_h)\n",
        "\t\t\ti=0\n",
        "\n",
        "\t\t\tfor i, nf in enumerate(nb_filters):\n",
        "\t\t\t\tname='conv%s'%i\n",
        "\n",
        "\t\t\t\t_h = Conv2D(nf, kernel_size, padding='same',activation='relu')(_h)\t\n",
        "\t\t\t\t\n",
        "\t\t\t\tif bn:\n",
        "\t\t\t\t\t_h = BatchNormalization()(_h)\n",
        "\t\t\t\tif i<2:\n",
        "\t\t\t\t\t_h = MaxPooling2D(pool_size=pool_size, padding='same',trainable=trainable)(_h)\n",
        "\t\t\t\ti+=1\n",
        "\t\t\t\t# kernel_size=(3,3)\n",
        "\t\t\t\t\n",
        "\n",
        "\t\t\t_f =_h\n",
        "\n",
        "\t\t\t_h = Flatten()(_h)\n",
        "\t\t\t# _h = Dropout(dropout)(_h)\n",
        "\t\t\t\n",
        "\t\t\t_h = Dense(1024,activation='relu',trainable=trainable)(_h)\n",
        "\t\t\t_h = Dropout(dropout)(_h)\n",
        "\t\t\t_h = Dense(1024,activation='relu',trainable=trainable)(_h)\n",
        "\t\t\t_h = Dropout(dropout)(_h)\n",
        "\t\t\t\n",
        "\t\t\treturn _h,_f\n",
        "\t\t\t\n",
        "\tdef create_model(self, input_shape=(1, 32, 32), dense_dim=1000, dy=10, nb_filters=[64, 128], kernel_size=(3, 3), pool_size=(2, 2), \n",
        "\t\t\tdropout=0.5, bn=True, output_activation='softmax', opt='adam'):\t\n",
        "\n",
        "\t\t\t[d1, d2, c] = input_shape\n",
        "\n",
        "\t\t\tif opt == 'adam':\n",
        "\t\t\t\topt = tf.keras.optimizers.Adam(lr=3e-4)\n",
        "\t\t\telif opt == 'rmsprop':\n",
        "\t\t\t\t#opt = RMSprop(lr=1e-4)\n",
        "\t\t\t\topt = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "\n",
        "\n",
        "\t\t\t#convnet e encoder\t\n",
        "\t\t\t_input = Input(shape=input_shape)\n",
        "\n",
        "\t\t\t_h,_f = self.extract_feat(_input,dense_dim,dy,nb_filters,kernel_size,pool_size,dropout,bn,output_activation,opt,trainable=True)\n",
        "\t\t\t\n",
        "\t\t\t_y1 = Dense(dy,activation='tanh',trainable=True)(_h)\n",
        "\t\t\t\n",
        "\t\t\t# _h,_f = self.extract_feat(_input,dense_dim,dy,nb_filters,kernel_size,pool_size,dropout,bn,output_activation,opt,trainable=True)\n",
        "\n",
        "\t\t\t[_,wflat, hflat, cflat]=_f.get_shape().as_list()\n",
        "\t\t\t#decoder\n",
        "\t\t\t_h = Dense (1024)(_h)\n",
        "\t\t\t_h = Dense (wflat* hflat* cflat)(_h)\n",
        "\t\t\t_h = Reshape((wflat, hflat, nb_filters[-1]))(_h)\n",
        "\t\t\tpool_size=(1,1)\n",
        "\t\t\ti=0\n",
        "\t\t\tfor nf in reversed(nb_filters):\n",
        "\n",
        "\n",
        "\t\t\t\t_h = tf.keras.layers.Conv2DTranspose(nf, kernel_size, strides=pool_size, padding='same',activation='relu')(_h)\n",
        "\t\t\t\tif bn:\n",
        "\t\t\t\t\t_h = BatchNormalization()(_h)\n",
        "\n",
        "\t\t\t\tif i>0:\n",
        "\t\t\t\t\tpool_size=(2,2)\n",
        "\t\t\t\ti+=1\n",
        "\t\t\t\t\n",
        "\n",
        "\t\t\t_h = Conv2D(1, kernel_size, padding='same', activation='relu')(_h)\n",
        "\n",
        "\n",
        "\n",
        "\t\t\tsgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\t\t\tself.convnet_model = Model(_input, _y1)\n",
        "\t\t\tself.convnet_model.compile(loss='mean_absolute_error', optimizer=tf.keras.optimizers.Adam(lr=3e-4))\t\n",
        "\n",
        "\t\t\tself.convae_model = Model(_input, _h)\t\n",
        "\t\t\tself.convae_model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(lr=3e-4))\n",
        "\t\t\tprint(self.convnet_model.summary())\n",
        "\t\t\tprint(self.convae_model.summary())\n",
        "\n",
        "\n",
        "\n",
        "\t\n",
        "\n",
        "\n",
        "\t###  just in case want to run convnet and convae separately, below are the training modules  ###\n",
        "###  just in case want to run convnet and convae separately, below are the training modules  ###\n",
        "\tdef fit_model(self, X, Y, Xu,supervised=None, nb_epoch=50, batch_size=128, shuffle=True,\n",
        "\t\t\tvalidation_data=None, test_data=None, PARAMDIR=None, CONF=None, tresh='none'):\n",
        "\n",
        "\t\n",
        "\t\n",
        "\t\thistory = {}\n",
        "\t\thistory['losses'] = []\n",
        "\t\thistory['accs'] = []\n",
        "\t\thistory['gen_losses'] = []\n",
        "\t\thistory['val_losses'] = []\n",
        "\t\thistory['val_accs'] = []\n",
        "\t\thistory['test_losses'] = []\n",
        "\t\thistory['test_accs'] = []\n",
        "\t\thistory['elapsed_times'] = []\n",
        "\n",
        "\t\tbest_ep = 1\n",
        "\t\t\n",
        "\t\t\n",
        "\n",
        "\t\tgdatagen = ImageDataGenerator(\n",
        "\t\t\t    featurewise_center=False, # set input mean to 0 over the dataset\n",
        "\t\t\t    samplewise_center=False, # set each sample mean to 0\n",
        "\t\t\t    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
        "\t\t\t    samplewise_std_normalization=False, # divide each input by its std\n",
        "\t\t\t    zca_whitening=False, # apply ZCA whitening\n",
        "\t\t\t    rotation_range=0.9, # randomly rotate images in the range (degrees, 0 to 180)\n",
        "\t\t\t    width_shift_range=0.4, # randomly shift images horizontally (fraction of total width)\n",
        "\t\t\t    height_shift_range=0.4, # randomly shift images vertically (fraction of total height)\n",
        "\t\t\t    horizontal_flip=0.4, # randomly flip images\n",
        "\t\t\t    vertical_flip=0.4\n",
        "\t\t\t) # randomly flip images\n",
        "\t\tep=[]\n",
        "\t\tcontrol=11\n",
        "\t\tfor e in range(nb_epoch):\n",
        "\t\t\tep.append(e)\n",
        "\t\t\tstart_t = time.time()\n",
        "\t\t\t\n",
        "\n",
        "\t\t\t## convnet training\n",
        "\t\t\tloss = 0.\n",
        "\t\t\tgen_loss = 0.\n",
        "\t\t\tloss_cat = 0.\n",
        "\t\t\tn_batch = 0\n",
        "\t\t\t(X_, Y_) = supervised\n",
        "\n",
        "\t\t\ttotal_batches = X.shape[0] / batch_size\n",
        "\t\t\tacc=-1\n",
        "\n",
        "\t\t\tfor (X_batch_, Y_batch_),(X_batch, Y_batch), (Xu_batch,Yu_batch) in zip(iterate_minibatches(X_, Y_, batchsize=batch_size, shuffle=shuffle),iterate_minibatches(X, Y, batchsize=batch_size, shuffle=shuffle),gdatagen.flow(Xu, np.copy(Xu), batch_size=batch_size, shuffle=shuffle)):\t\t\t\t\n",
        "\t\t\t\tXu_batch = get_impulse_noise(Xu_batch, 0.5)\n",
        "\t\t\t\tprint( X_batch.shape[0], \" \",Xu_batch.shape[0], \" \",X_batch_.shape[0])\n",
        "\t\t\t\tl = self.convae_model.train_on_batch(Xu_batch, Yu_batch)\n",
        "\t\t\t\tgen_loss += l\n",
        "\t\t\t\t\n",
        "\t\t\t\tl = self.convnet_model.train_on_batch(X_batch, Y_batch)\n",
        "\t\t\t\tloss += l\n",
        "\t\t\t\tif X_.shape[0] != 0:\n",
        "\t\t\t\t\tl = self.convnet_model.train_on_batch(X_batch_, Y_batch_)\n",
        "\t\t\t\t\tloss_cat += l\n",
        "\n",
        "\n",
        "\t\t\t\tn_batch += 1\n",
        "\t\t\t\tif n_batch >= total_batches:\n",
        "\t\t\t\t\tbreak\n",
        "\n",
        "\n",
        "\t\t\t\t\n",
        "\n",
        "\t\t\tloss /= n_batch\n",
        "\t\t\thistory['losses'].append(loss)\n",
        "\t\t\t\n",
        "\t\t\tgen_loss /= n_batch\n",
        "\t\t\thistory['gen_losses'].append(gen_loss)\n",
        "\t\t\t\t\t\t\n",
        "\t\t\telapsed_t = time.time() - start_t\n",
        "\t\t\thistory['elapsed_times'].append(elapsed_t)\n",
        "\n",
        "\t\t\t\t\t\t\n",
        "\t\t\tval_loss = -1\n",
        "\t\t\tval_acc = -1\n",
        "\t\t\tbest_val_acc = -1\n",
        "\t\t\tif validation_data is not None:\n",
        "\t\t\t\t(X_val, Y_val) = validation_data\n",
        "\t\t\t\tval_loss = 0.\n",
        "\t\t\t\tn_batch = 0\n",
        "\t\t\t\tfor Xv, Yv in iterate_minibatches(X_val, Y_val ,batch_size, shuffle=False):\n",
        "\t\t\t\t\tl = self.convnet_model.test_on_batch(Xv, Yv)\n",
        "\t\t\t\t\tval_loss += l\n",
        "\t\t\t\t\tn_batch += 1\n",
        "\t\t\t\tval_loss /= n_batch\n",
        "\t\t\t\thistory['val_losses'].append(val_loss)\n",
        "\n",
        "\t\t\t\n",
        "\t\t\ttest_loss = -1\n",
        "\t\t\ttest_acc = -1\n",
        "\t\t\tif test_data is not None:\n",
        "\t\t\t\t(X_test, Y_test) = test_data\n",
        "\t\t\t\ttest_loss = 0.\n",
        "\t\t\t\tn_batch = 0\n",
        "\t\t\t\tfor Xt, Yt in iterate_minibatches(X_test, Y_test, batch_size, shuffle=False):\n",
        "\t\t\t\t\tl = self.convnet_model.test_on_batch(Xt, Yt)\n",
        "\t\t\t\t\ttest_loss += l\n",
        "\t\t\t\t\tn_batch += 1\n",
        "\n",
        "\t\t\t\ttest_loss /= n_batch\n",
        "\n",
        "\t\t\tprint('Epoch-%d: (loss: %.3f, gen_loss: %.3f), (val_loss: %.3f), (test_Loss: %.3f)  -- %.2f sec' % \\\n",
        "\t\t\t\t((e+1), loss, gen_loss, val_loss, test_loss,  elapsed_t))\n",
        "\n",
        "\n",
        "\t\t\tcontrol+=1\n",
        "\t\t\tif control>=10:\n",
        "\t\t\t\tcontrol=0\n",
        "\n",
        "\t\t\t\tacc = new_accuracy(self.convnet_model.predict(X), Y)\n",
        "\n",
        "\t\t\t\tval_acc = new_accuracy(self.convnet_model.predict(X_val), Y_val)\n",
        "\n",
        "\t\t\t\ttest_acc = new_accuracy(self.convnet_model.predict(X_test), Y_test)\n",
        "\t\t\t\tsave_weights(self.convnet_model, PARAMDIR,CONF)\n",
        "\t\t\t\t#save_weights(self.convae_model, CONF, 'ours_reconstrutor_{}'.format(tresh))\n",
        "\n",
        "\t\t\t\tprint('Epoch-%d: (loss: %.3f, acc: %.3f, gen_loss: %.3f), (val_loss: %.3f, val_acc: %.3f), (test_Loss: %.3f, test_acc: %.3f)  -- %.2f sec' % \\\n",
        "\t\t\t\t((e+1), loss, acc, gen_loss, val_loss, val_acc, test_loss, test_acc,  elapsed_t))"
      ],
      "metadata": {
        "id": "RUxNXMumVHQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " # KTF.set_session(get_session())\n",
        "# Load datasets\n",
        "animal=['horse','human','dog']\n",
        "print('Load datasets')\n",
        "dir_source = '/drive/My Drive/Dataset_mestrado/training_human_32x32.csv'\n",
        "X_source, _, Y_source = load(dir_source)\n",
        "print (X_source.shape)\n",
        "for name_animal in animal:\n",
        "\n",
        "        name_animal='cat'\n",
        "        dir_target='/drive/My Drive/Dataset_mestrado/training_cat_32x32.csv'\n",
        "        X_target, _, Y_target = load(dir_target)\n",
        "        PARAMDIR='/drive/My Drive/Dataset_mestrado/weights/'+name_animal+'/'\n",
        "        create_folder(PARAMDIR)\n",
        "        param=[0,10,50,100,200,500,1000]\n",
        "\n",
        "\n",
        "        for tresh in param:\n",
        "            k.set_session(get_session())\n",
        "            CONF='ours_horse_tresh_'+str(tresh)\n",
        "            print('Create Model')\n",
        "            model = MODEL()\n",
        "            nb_classes=6#nb_filters=[300,250,200,150]\n",
        "            input_shape = (X_source.shape[1], X_source.shape[2], X_source.shape[3])\n",
        "            print (input_shape)\n",
        "            model.create_model(input_shape=input_shape, dense_dim=500, dy=nb_classes, nb_filters=[300,200,150,100], kernel_size=(3,3), pool_size=(2, 2), \n",
        "                    dropout=0.5, bn=False, output_activation='softmax', opt='rmsprop')\n",
        "            #tresh=100\n",
        "            print('Train supervised...')\n",
        "            print (\"name_animal \",name_animal)\n",
        "\n",
        "            print( X_target[:tresh].shape)\n",
        "            if tresh ==0:\n",
        "            \tsupervised=(X_target[:1], Y_target[:1])\n",
        "            else:\n",
        "            \tsupervised=(X_target[:tresh], Y_target[:tresh])\n",
        "\n",
        "            model.fit_model(X_source, Y_source, X_target,supervised=supervised, validation_data=(X_source,Y_source), \n",
        "                    test_data=(X_target[1000:],Y_target[1000:]),\n",
        "                    nb_epoch=200, batch_size=500,\n",
        "                    PARAMDIR=PARAMDIR, CONF=CONF,tresh=tresh\n",
        "            )\n",
        "            del model\n",
        "            K.clear_session()\n",
        "\t\t\t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xCN9FSm2VVlr",
        "outputId": "4ee5d9cd-9f93-4a0a-8ccd-0b86fdec1a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load datasets\n",
            "source  left_eye_center_x     8560\n",
            "left_eye_center_y     8560\n",
            "right_eye_center_x    8560\n",
            "right_eye_center_y    8560\n",
            "nose_tip_x            8560\n",
            "nose_tip_y            8560\n",
            "image                 8560\n",
            "image_gt              8560\n",
            "dtype: int64\n",
            "source  left_eye_center_x     8560\n",
            "left_eye_center_y     8560\n",
            "right_eye_center_x    8560\n",
            "right_eye_center_y    8560\n",
            "nose_tip_x            8560\n",
            "nose_tip_y            8560\n",
            "image                 8560\n",
            "image_gt              8560\n",
            "dtype: int64\n",
            "(8560, 32, 32, 1)\n",
            "source  left_eye_center_x     9846\n",
            "left_eye_center_y     9846\n",
            "right_eye_center_x    9846\n",
            "right_eye_center_y    9846\n",
            "nose_tip_x            9846\n",
            "nose_tip_y            9846\n",
            "image                 9846\n",
            "image_gt              9846\n",
            "dtype: int64\n",
            "source  left_eye_center_x     9846\n",
            "left_eye_center_y     9846\n",
            "right_eye_center_x    9846\n",
            "right_eye_center_y    9846\n",
            "nose_tip_x            9846\n",
            "nose_tip_y            9846\n",
            "image                 9846\n",
            "image_gt              9846\n",
            "dtype: int64\n",
            "Create Model\n",
            "(32, 32, 1)\n",
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 32, 32, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 32, 32, 300)       3000      \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 16, 16, 300)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 16, 16, 200)       540200    \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 8, 8, 200)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 8, 8, 150)         270150    \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 8, 8, 100)         135100    \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 1024)              6554624   \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 6)                 6150      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,558,824\n",
            "Trainable params: 8,558,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 32, 32, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 32, 32, 300)       3000      \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 16, 16, 300)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 16, 16, 200)       540200    \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 8, 8, 200)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 8, 8, 150)         270150    \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 8, 8, 100)         135100    \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 1024)              6554624   \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 6400)              6560000   \n",
            "                                                                 \n",
            " reshape_9 (Reshape)         (None, 8, 8, 100)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_32 (Conv2D  (None, 8, 8, 100)        90100     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_33 (Conv2D  (None, 8, 8, 150)        135150    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_34 (Conv2D  (None, 16, 16, 200)      270200    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_35 (Conv2D  (None, 32, 32, 300)      540300    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_48 (Conv2D)          (None, 32, 32, 1)         2701      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,200,725\n",
            "Trainable params: 17,200,725\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Train supervised...\n",
            "name_animal  cat\n",
            "(0, 32, 32, 1)\n",
            "500   500   1\n",
            "Epoch-1: (loss: 0.346, gen_loss: 0.242), (val_loss: 0.231), (test_Loss: 0.196)  -- 47.09 sec\n",
            " == save weights == \n",
            "/drive/My Drive/Dataset_mestrado/weights/cat/\n",
            "Epoch-1: (loss: 0.346, acc: 0.424, gen_loss: 0.242), (val_loss: 0.231, val_acc: 0.424), (test_Loss: 0.196, test_acc: 0.238)  -- 47.09 sec\n",
            "500   500   1\n",
            "Epoch-2: (loss: 0.353, gen_loss: 0.247), (val_loss: 0.233), (test_Loss: 0.211)  -- 42.28 sec\n",
            "500   500   1\n",
            "Epoch-3: (loss: 0.378, gen_loss: 0.233), (val_loss: 0.234), (test_Loss: 0.252)  -- 40.67 sec\n",
            "500   500   1\n",
            "Epoch-4: (loss: 0.363, gen_loss: 0.200), (val_loss: 0.244), (test_Loss: 0.283)  -- 41.90 sec\n",
            "500   500   1\n",
            "Epoch-5: (loss: 0.373, gen_loss: 0.136), (val_loss: 0.239), (test_Loss: 0.281)  -- 43.50 sec\n",
            "500   500   1\n",
            "Epoch-6: (loss: 0.353, gen_loss: 0.070), (val_loss: 0.222), (test_Loss: 0.257)  -- 40.50 sec\n",
            "500   500   1\n",
            "Epoch-7: (loss: 0.277, gen_loss: 0.190), (val_loss: 0.267), (test_Loss: 0.281)  -- 41.91 sec\n",
            "500   500   1\n",
            "Epoch-8: (loss: 0.274, gen_loss: 0.090), (val_loss: 0.267), (test_Loss: 0.277)  -- 43.26 sec\n",
            "500   500   1\n",
            "Epoch-9: (loss: 0.284, gen_loss: 0.134), (val_loss: 0.241), (test_Loss: 0.248)  -- 41.00 sec\n",
            "500   500   1\n",
            "Epoch-10: (loss: 0.233, gen_loss: 0.128), (val_loss: 0.248), (test_Loss: 0.205)  -- 40.07 sec\n",
            "500   500   1\n",
            "Epoch-11: (loss: 0.278, gen_loss: 0.093), (val_loss: 0.331), (test_Loss: 0.246)  -- 43.01 sec\n",
            " == save weights == \n",
            "/drive/My Drive/Dataset_mestrado/weights/cat/\n",
            "Epoch-11: (loss: 0.278, acc: 0.117, gen_loss: 0.093), (val_loss: 0.331, val_acc: 0.117), (test_Loss: 0.246, test_acc: 0.147)  -- 43.01 sec\n",
            "500   500   1\n",
            "Epoch-12: (loss: 0.385, gen_loss: 0.062), (val_loss: 0.344), (test_Loss: 0.255)  -- 41.79 sec\n",
            "500   500   1\n",
            "Epoch-13: (loss: 0.360, gen_loss: 0.057), (val_loss: 0.288), (test_Loss: 0.217)  -- 42.49 sec\n",
            "500   500   1\n",
            "Epoch-14: (loss: 0.348, gen_loss: 0.057), (val_loss: 0.253), (test_Loss: 0.205)  -- 43.17 sec\n",
            "500   500   1\n",
            "Epoch-15: (loss: 0.278, gen_loss: 0.059), (val_loss: 0.246), (test_Loss: 0.211)  -- 40.73 sec\n",
            "500   500   1\n",
            "Epoch-16: (loss: 0.287, gen_loss: 0.055), (val_loss: 0.244), (test_Loss: 0.218)  -- 42.48 sec\n",
            "500   500   1\n",
            "Epoch-17: (loss: 0.258, gen_loss: 0.054), (val_loss: 0.241), (test_Loss: 0.225)  -- 45.53 sec\n",
            "500   500   1\n",
            "Epoch-18: (loss: 0.242, gen_loss: 0.060), (val_loss: 0.237), (test_Loss: 0.231)  -- 41.36 sec\n",
            "500   500   1\n",
            "Epoch-19: (loss: 0.243, gen_loss: 0.057), (val_loss: 0.238), (test_Loss: 0.235)  -- 42.49 sec\n",
            "500   500   1\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-b597c58d50f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m                     \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                     \u001b[0mPARAMDIR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPARAMDIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtresh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             )\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-61caa0d2e009>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(self, X, Y, Xu, supervised, nb_epoch, batch_size, shuffle, validation_data, test_data, PARAMDIR, CONF, tresh)\u001b[0m\n\u001b[1;32m    178\u001b[0m                                 \u001b[0mgen_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m                                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mX_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2091\u001b[0m                                                     class_weight)\n\u001b[1;32m   2092\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2093\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2095\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}