# 2StepsLearning
[Project Page](https://www.verlab.dcc.ufmg.br/portfolio-item/detecting-landmarks-on-faces-in-different-domains/) [Paper](https://www.verlab.dcc.ufmg.br/fradeicip2018/) 

## Train models
1. Go to Notebook/train_models.ipynp
2. Get yours [datasets] (https://drive.google.com/drive/folders/1VadYbCgZ_EEfaPyhYM4L84Ci0keBJv9B?usp=sharing):
  source: training_human_32x32.csv
  target for example: training_cat_32x32
3. Put dataset files in your drive and change the path in your code to new path (dir_source, dir_target)

## Compare models

1. You can use Utils/Graficos.py and Utils/radar_grafico_metodos.py to generate result graphs
2. The weights used are in the Dissertation [link](https://drive.google.com/drive/folders/1TMwyM6mT7Pdf3DcWIPudXAXJgE9GBwWK?usp=sharing)
3. You need to download the weights and set the paths in your codes
4. You need to Download the datasets and set the path in your codes [link] (https://drive.google.com/drive/folders/1VadYbCgZ_EEfaPyhYM4L84Ci0keBJv9B?usp=sharing)
